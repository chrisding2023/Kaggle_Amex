{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56940382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import random\n",
    "import warnings\n",
    "import itertools\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings('ignore')\n",
    "from itertools import combinations\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "from catboost import CatBoostClassifier\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7c9dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"train_addlag.pkl\", compression=\"gzip\")\n",
    "test = pd.read_pickle(\"test_addlag.pkl\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12036b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1365\n"
     ]
    }
   ],
   "source": [
    "# Get feature list\n",
    "features = [col for col in train.columns if col not in ['customer_ID', 'target']]\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f0c9365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "# Created by https://www.kaggle.com/yunchonggan\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/328020\n",
    "def amex_metric_np(preds: np.ndarray, target: np.ndarray) -> float:\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "# we still need the official metric since the faster version above is slightly off\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90f8d30e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1365 features...\n",
      "[0]\ttrain-logloss:0.67363\ttrain-amex:0.71136\teval-logloss:0.67372\teval-amex:0.70999\n",
      "[1]\ttrain-logloss:0.65555\ttrain-amex:0.72523\teval-logloss:0.65558\teval-amex:0.72134\n",
      "[2]\ttrain-logloss:0.63801\ttrain-amex:0.73153\teval-logloss:0.63825\teval-amex:0.72853\n",
      "[3]\ttrain-logloss:0.62174\ttrain-amex:0.73286\teval-logloss:0.62185\teval-amex:0.72965\n",
      "[4]\ttrain-logloss:0.60603\ttrain-amex:0.73520\teval-logloss:0.60634\teval-amex:0.73209\n",
      "[5]\ttrain-logloss:0.59135\ttrain-amex:0.73505\teval-logloss:0.59162\teval-amex:0.73288\n",
      "[6]\ttrain-logloss:0.57745\ttrain-amex:0.73886\teval-logloss:0.57772\teval-amex:0.73524\n",
      "[7]\ttrain-logloss:0.56421\ttrain-amex:0.74164\teval-logloss:0.56453\teval-amex:0.73761\n",
      "[8]\ttrain-logloss:0.55163\ttrain-amex:0.74304\teval-logloss:0.55200\teval-amex:0.74018\n",
      "[9]\ttrain-logloss:0.53941\ttrain-amex:0.74450\teval-logloss:0.53994\teval-amex:0.74226\n",
      "[10]\ttrain-logloss:0.52813\ttrain-amex:0.74598\teval-logloss:0.52855\teval-amex:0.74439\n",
      "[11]\ttrain-logloss:0.51699\ttrain-amex:0.74675\teval-logloss:0.51752\teval-amex:0.74477\n",
      "[12]\ttrain-logloss:0.50637\ttrain-amex:0.74688\teval-logloss:0.50701\teval-amex:0.74482\n",
      "[13]\ttrain-logloss:0.49637\ttrain-amex:0.74758\teval-logloss:0.49700\teval-amex:0.74667\n",
      "[14]\ttrain-logloss:0.48671\ttrain-amex:0.74817\teval-logloss:0.48740\teval-amex:0.74627\n",
      "[15]\ttrain-logloss:0.47749\ttrain-amex:0.74900\teval-logloss:0.47823\teval-amex:0.74555\n",
      "[16]\ttrain-logloss:0.46864\ttrain-amex:0.74992\teval-logloss:0.46942\teval-amex:0.74692\n",
      "[17]\ttrain-logloss:0.46018\ttrain-amex:0.75019\teval-logloss:0.46101\teval-amex:0.74866\n",
      "[18]\ttrain-logloss:0.45209\ttrain-amex:0.75123\teval-logloss:0.45295\teval-amex:0.74906\n",
      "[19]\ttrain-logloss:0.44433\ttrain-amex:0.75165\teval-logloss:0.44523\teval-amex:0.74964\n",
      "[20]\ttrain-logloss:0.43692\ttrain-amex:0.75233\teval-logloss:0.43781\teval-amex:0.75095\n",
      "[21]\ttrain-logloss:0.42972\ttrain-amex:0.75266\teval-logloss:0.43066\teval-amex:0.75148\n",
      "[22]\ttrain-logloss:0.42284\ttrain-amex:0.75341\teval-logloss:0.42383\teval-amex:0.75189\n",
      "[23]\ttrain-logloss:0.41625\ttrain-amex:0.75396\teval-logloss:0.41727\teval-amex:0.75177\n",
      "[24]\ttrain-logloss:0.40987\ttrain-amex:0.75466\teval-logloss:0.41093\teval-amex:0.75275\n",
      "[25]\ttrain-logloss:0.40369\ttrain-amex:0.75511\teval-logloss:0.40480\teval-amex:0.75351\n",
      "[26]\ttrain-logloss:0.39786\ttrain-amex:0.75579\teval-logloss:0.39895\teval-amex:0.75427\n",
      "[27]\ttrain-logloss:0.39213\ttrain-amex:0.75646\teval-logloss:0.39331\teval-amex:0.75485\n",
      "[28]\ttrain-logloss:0.38670\ttrain-amex:0.75691\teval-logloss:0.38791\teval-amex:0.75468\n",
      "[29]\ttrain-logloss:0.38142\ttrain-amex:0.75763\teval-logloss:0.38270\teval-amex:0.75537\n",
      "[30]\ttrain-logloss:0.37637\ttrain-amex:0.75819\teval-logloss:0.37771\teval-amex:0.75535\n",
      "[31]\ttrain-logloss:0.37160\ttrain-amex:0.75867\teval-logloss:0.37296\teval-amex:0.75584\n",
      "[32]\ttrain-logloss:0.36684\ttrain-amex:0.75922\teval-logloss:0.36829\teval-amex:0.75638\n",
      "[33]\ttrain-logloss:0.36237\ttrain-amex:0.75963\teval-logloss:0.36382\teval-amex:0.75633\n",
      "[34]\ttrain-logloss:0.35803\ttrain-amex:0.76018\teval-logloss:0.35952\teval-amex:0.75641\n",
      "[35]\ttrain-logloss:0.35379\ttrain-amex:0.76092\teval-logloss:0.35533\teval-amex:0.75716\n",
      "[36]\ttrain-logloss:0.34975\ttrain-amex:0.76116\teval-logloss:0.35132\teval-amex:0.75687\n",
      "[37]\ttrain-logloss:0.34583\ttrain-amex:0.76164\teval-logloss:0.34748\teval-amex:0.75751\n",
      "[38]\ttrain-logloss:0.34200\ttrain-amex:0.76198\teval-logloss:0.34373\teval-amex:0.75759\n",
      "[39]\ttrain-logloss:0.33835\ttrain-amex:0.76268\teval-logloss:0.34012\teval-amex:0.75736\n",
      "[40]\ttrain-logloss:0.33481\ttrain-amex:0.76304\teval-logloss:0.33666\teval-amex:0.75749\n",
      "[41]\ttrain-logloss:0.33142\ttrain-amex:0.76335\teval-logloss:0.33330\teval-amex:0.75793\n",
      "[42]\ttrain-logloss:0.32811\ttrain-amex:0.76379\teval-logloss:0.33002\teval-amex:0.75791\n",
      "[43]\ttrain-logloss:0.32496\ttrain-amex:0.76400\teval-logloss:0.32691\teval-amex:0.75895\n",
      "[44]\ttrain-logloss:0.32184\ttrain-amex:0.76478\teval-logloss:0.32387\teval-amex:0.75919\n",
      "[45]\ttrain-logloss:0.31886\ttrain-amex:0.76480\teval-logloss:0.32092\teval-amex:0.75919\n",
      "[46]\ttrain-logloss:0.31599\ttrain-amex:0.76530\teval-logloss:0.31806\teval-amex:0.75919\n",
      "[47]\ttrain-logloss:0.31317\ttrain-amex:0.76558\teval-logloss:0.31534\teval-amex:0.76052\n",
      "[48]\ttrain-logloss:0.31050\ttrain-amex:0.76604\teval-logloss:0.31268\teval-amex:0.76038\n",
      "[49]\ttrain-logloss:0.30787\ttrain-amex:0.76657\teval-logloss:0.31015\teval-amex:0.76036\n",
      "[50]\ttrain-logloss:0.30539\ttrain-amex:0.76680\teval-logloss:0.30768\teval-amex:0.76110\n",
      "[51]\ttrain-logloss:0.30296\ttrain-amex:0.76719\teval-logloss:0.30527\teval-amex:0.76162\n",
      "[52]\ttrain-logloss:0.30055\ttrain-amex:0.76744\teval-logloss:0.30296\teval-amex:0.76172\n",
      "[53]\ttrain-logloss:0.29830\ttrain-amex:0.76782\teval-logloss:0.30073\teval-amex:0.76218\n",
      "[54]\ttrain-logloss:0.29609\ttrain-amex:0.76802\teval-logloss:0.29859\teval-amex:0.76271\n",
      "[55]\ttrain-logloss:0.29392\ttrain-amex:0.76849\teval-logloss:0.29650\teval-amex:0.76296\n",
      "[56]\ttrain-logloss:0.29185\ttrain-amex:0.76831\teval-logloss:0.29446\teval-amex:0.76256\n",
      "[57]\ttrain-logloss:0.28982\ttrain-amex:0.76889\teval-logloss:0.29249\teval-amex:0.76302\n",
      "[58]\ttrain-logloss:0.28789\ttrain-amex:0.76910\teval-logloss:0.29059\teval-amex:0.76346\n",
      "[59]\ttrain-logloss:0.28600\ttrain-amex:0.76943\teval-logloss:0.28874\teval-amex:0.76353\n",
      "[60]\ttrain-logloss:0.28414\ttrain-amex:0.76953\teval-logloss:0.28692\teval-amex:0.76375\n",
      "[61]\ttrain-logloss:0.28238\ttrain-amex:0.77014\teval-logloss:0.28519\teval-amex:0.76369\n",
      "[62]\ttrain-logloss:0.28065\ttrain-amex:0.77017\teval-logloss:0.28350\teval-amex:0.76418\n",
      "[63]\ttrain-logloss:0.27899\ttrain-amex:0.77058\teval-logloss:0.28186\teval-amex:0.76417\n",
      "[64]\ttrain-logloss:0.27736\ttrain-amex:0.77108\teval-logloss:0.28031\teval-amex:0.76468\n",
      "[65]\ttrain-logloss:0.27577\ttrain-amex:0.77146\teval-logloss:0.27879\teval-amex:0.76501\n",
      "[66]\ttrain-logloss:0.27427\ttrain-amex:0.77217\teval-logloss:0.27730\teval-amex:0.76540\n",
      "[67]\ttrain-logloss:0.27278\ttrain-amex:0.77233\teval-logloss:0.27585\teval-amex:0.76556\n",
      "[68]\ttrain-logloss:0.27131\ttrain-amex:0.77233\teval-logloss:0.27444\teval-amex:0.76551\n",
      "[69]\ttrain-logloss:0.26990\ttrain-amex:0.77264\teval-logloss:0.27308\teval-amex:0.76589\n",
      "[70]\ttrain-logloss:0.26854\ttrain-amex:0.77293\teval-logloss:0.27177\teval-amex:0.76574\n",
      "[71]\ttrain-logloss:0.26724\ttrain-amex:0.77313\teval-logloss:0.27050\teval-amex:0.76645\n",
      "[72]\ttrain-logloss:0.26598\ttrain-amex:0.77346\teval-logloss:0.26926\teval-amex:0.76647\n",
      "[73]\ttrain-logloss:0.26473\ttrain-amex:0.77374\teval-logloss:0.26807\teval-amex:0.76682\n",
      "[74]\ttrain-logloss:0.26356\ttrain-amex:0.77371\teval-logloss:0.26695\teval-amex:0.76726\n",
      "[75]\ttrain-logloss:0.26238\ttrain-amex:0.77413\teval-logloss:0.26582\teval-amex:0.76733\n",
      "[76]\ttrain-logloss:0.26128\ttrain-amex:0.77441\teval-logloss:0.26473\teval-amex:0.76792\n",
      "[77]\ttrain-logloss:0.26017\ttrain-amex:0.77464\teval-logloss:0.26368\teval-amex:0.76801\n",
      "[78]\ttrain-logloss:0.25909\ttrain-amex:0.77491\teval-logloss:0.26267\teval-amex:0.76806\n",
      "[79]\ttrain-logloss:0.25805\ttrain-amex:0.77512\teval-logloss:0.26167\teval-amex:0.76828\n",
      "[80]\ttrain-logloss:0.25704\ttrain-amex:0.77554\teval-logloss:0.26068\teval-amex:0.76849\n",
      "[81]\ttrain-logloss:0.25605\ttrain-amex:0.77577\teval-logloss:0.25976\teval-amex:0.76875\n",
      "[82]\ttrain-logloss:0.25509\ttrain-amex:0.77574\teval-logloss:0.25885\teval-amex:0.76885\n",
      "[83]\ttrain-logloss:0.25414\ttrain-amex:0.77580\teval-logloss:0.25797\teval-amex:0.76890\n",
      "[84]\ttrain-logloss:0.25326\ttrain-amex:0.77617\teval-logloss:0.25710\teval-amex:0.76932\n",
      "[85]\ttrain-logloss:0.25237\ttrain-amex:0.77658\teval-logloss:0.25627\teval-amex:0.76929\n",
      "[86]\ttrain-logloss:0.25153\ttrain-amex:0.77687\teval-logloss:0.25546\teval-amex:0.76946\n",
      "[87]\ttrain-logloss:0.25068\ttrain-amex:0.77699\teval-logloss:0.25467\teval-amex:0.76916\n",
      "[88]\ttrain-logloss:0.24989\ttrain-amex:0.77702\teval-logloss:0.25390\teval-amex:0.76991\n",
      "[89]\ttrain-logloss:0.24912\ttrain-amex:0.77723\teval-logloss:0.25317\teval-amex:0.77017\n",
      "[90]\ttrain-logloss:0.24833\ttrain-amex:0.77737\teval-logloss:0.25246\teval-amex:0.77033\n",
      "[91]\ttrain-logloss:0.24759\ttrain-amex:0.77785\teval-logloss:0.25176\teval-amex:0.77029\n",
      "[92]\ttrain-logloss:0.24688\ttrain-amex:0.77801\teval-logloss:0.25106\teval-amex:0.77015\n",
      "[93]\ttrain-logloss:0.24618\ttrain-amex:0.77831\teval-logloss:0.25041\teval-amex:0.77044\n",
      "[94]\ttrain-logloss:0.24549\ttrain-amex:0.77852\teval-logloss:0.24974\teval-amex:0.77065\n",
      "[95]\ttrain-logloss:0.24480\ttrain-amex:0.77870\teval-logloss:0.24910\teval-amex:0.77079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96]\ttrain-logloss:0.24417\ttrain-amex:0.77894\teval-logloss:0.24849\teval-amex:0.77144\n",
      "[97]\ttrain-logloss:0.24353\ttrain-amex:0.77920\teval-logloss:0.24789\teval-amex:0.77127\n",
      "[98]\ttrain-logloss:0.24291\ttrain-amex:0.77945\teval-logloss:0.24732\teval-amex:0.77184\n",
      "[99]\ttrain-logloss:0.24234\ttrain-amex:0.77970\teval-logloss:0.24677\teval-amex:0.77247\n",
      "[100]\ttrain-logloss:0.24173\ttrain-amex:0.78004\teval-logloss:0.24621\teval-amex:0.77231\n",
      "[101]\ttrain-logloss:0.24113\ttrain-amex:0.78008\teval-logloss:0.24567\teval-amex:0.77228\n",
      "[102]\ttrain-logloss:0.24057\ttrain-amex:0.78043\teval-logloss:0.24515\teval-amex:0.77296\n",
      "[103]\ttrain-logloss:0.24001\ttrain-amex:0.78060\teval-logloss:0.24464\teval-amex:0.77304\n",
      "[104]\ttrain-logloss:0.23950\ttrain-amex:0.78079\teval-logloss:0.24415\teval-amex:0.77291\n",
      "[105]\ttrain-logloss:0.23894\ttrain-amex:0.78091\teval-logloss:0.24365\teval-amex:0.77290\n",
      "[106]\ttrain-logloss:0.23844\ttrain-amex:0.78108\teval-logloss:0.24317\teval-amex:0.77342\n",
      "[107]\ttrain-logloss:0.23795\ttrain-amex:0.78124\teval-logloss:0.24271\teval-amex:0.77354\n",
      "[108]\ttrain-logloss:0.23746\ttrain-amex:0.78159\teval-logloss:0.24227\teval-amex:0.77340\n",
      "[109]\ttrain-logloss:0.23695\ttrain-amex:0.78177\teval-logloss:0.24180\teval-amex:0.77355\n",
      "[110]\ttrain-logloss:0.23650\ttrain-amex:0.78227\teval-logloss:0.24138\teval-amex:0.77380\n",
      "[111]\ttrain-logloss:0.23603\ttrain-amex:0.78237\teval-logloss:0.24099\teval-amex:0.77399\n",
      "[112]\ttrain-logloss:0.23559\ttrain-amex:0.78268\teval-logloss:0.24057\teval-amex:0.77419\n",
      "[113]\ttrain-logloss:0.23512\ttrain-amex:0.78281\teval-logloss:0.24016\teval-amex:0.77458\n",
      "[114]\ttrain-logloss:0.23469\ttrain-amex:0.78291\teval-logloss:0.23977\teval-amex:0.77476\n",
      "[115]\ttrain-logloss:0.23428\ttrain-amex:0.78336\teval-logloss:0.23940\teval-amex:0.77459\n",
      "[116]\ttrain-logloss:0.23388\ttrain-amex:0.78360\teval-logloss:0.23905\teval-amex:0.77509\n",
      "[117]\ttrain-logloss:0.23349\ttrain-amex:0.78373\teval-logloss:0.23872\teval-amex:0.77553\n",
      "[118]\ttrain-logloss:0.23310\ttrain-amex:0.78398\teval-logloss:0.23836\teval-amex:0.77576\n",
      "[119]\ttrain-logloss:0.23270\ttrain-amex:0.78424\teval-logloss:0.23802\teval-amex:0.77596\n",
      "[120]\ttrain-logloss:0.23234\ttrain-amex:0.78435\teval-logloss:0.23770\teval-amex:0.77624\n",
      "[121]\ttrain-logloss:0.23198\ttrain-amex:0.78452\teval-logloss:0.23737\teval-amex:0.77626\n",
      "[122]\ttrain-logloss:0.23164\ttrain-amex:0.78495\teval-logloss:0.23707\teval-amex:0.77620\n",
      "[123]\ttrain-logloss:0.23131\ttrain-amex:0.78517\teval-logloss:0.23676\teval-amex:0.77628\n",
      "[124]\ttrain-logloss:0.23099\ttrain-amex:0.78518\teval-logloss:0.23650\teval-amex:0.77630\n",
      "[125]\ttrain-logloss:0.23068\ttrain-amex:0.78527\teval-logloss:0.23622\teval-amex:0.77639\n",
      "[126]\ttrain-logloss:0.23039\ttrain-amex:0.78555\teval-logloss:0.23596\teval-amex:0.77678\n",
      "[127]\ttrain-logloss:0.23008\ttrain-amex:0.78562\teval-logloss:0.23567\teval-amex:0.77703\n",
      "[128]\ttrain-logloss:0.22978\ttrain-amex:0.78587\teval-logloss:0.23541\teval-amex:0.77687\n",
      "[129]\ttrain-logloss:0.22947\ttrain-amex:0.78609\teval-logloss:0.23514\teval-amex:0.77728\n",
      "[130]\ttrain-logloss:0.22919\ttrain-amex:0.78621\teval-logloss:0.23489\teval-amex:0.77697\n",
      "[131]\ttrain-logloss:0.22887\ttrain-amex:0.78642\teval-logloss:0.23461\teval-amex:0.77718\n",
      "[132]\ttrain-logloss:0.22858\ttrain-amex:0.78654\teval-logloss:0.23436\teval-amex:0.77722\n",
      "[133]\ttrain-logloss:0.22831\ttrain-amex:0.78660\teval-logloss:0.23412\teval-amex:0.77726\n",
      "[134]\ttrain-logloss:0.22803\ttrain-amex:0.78684\teval-logloss:0.23389\teval-amex:0.77738\n",
      "[135]\ttrain-logloss:0.22775\ttrain-amex:0.78719\teval-logloss:0.23365\teval-amex:0.77774\n",
      "[136]\ttrain-logloss:0.22747\ttrain-amex:0.78733\teval-logloss:0.23343\teval-amex:0.77758\n",
      "[137]\ttrain-logloss:0.22721\ttrain-amex:0.78753\teval-logloss:0.23321\teval-amex:0.77789\n",
      "[138]\ttrain-logloss:0.22697\ttrain-amex:0.78788\teval-logloss:0.23298\teval-amex:0.77772\n",
      "[139]\ttrain-logloss:0.22671\ttrain-amex:0.78813\teval-logloss:0.23276\teval-amex:0.77812\n",
      "[140]\ttrain-logloss:0.22647\ttrain-amex:0.78819\teval-logloss:0.23255\teval-amex:0.77814\n",
      "[141]\ttrain-logloss:0.22621\ttrain-amex:0.78827\teval-logloss:0.23234\teval-amex:0.77857\n",
      "[142]\ttrain-logloss:0.22597\ttrain-amex:0.78836\teval-logloss:0.23214\teval-amex:0.77842\n",
      "[143]\ttrain-logloss:0.22575\ttrain-amex:0.78859\teval-logloss:0.23195\teval-amex:0.77891\n",
      "[144]\ttrain-logloss:0.22554\ttrain-amex:0.78877\teval-logloss:0.23177\teval-amex:0.77862\n",
      "[145]\ttrain-logloss:0.22529\ttrain-amex:0.78876\teval-logloss:0.23156\teval-amex:0.77883\n",
      "[146]\ttrain-logloss:0.22505\ttrain-amex:0.78884\teval-logloss:0.23138\teval-amex:0.77878\n",
      "[147]\ttrain-logloss:0.22482\ttrain-amex:0.78921\teval-logloss:0.23119\teval-amex:0.77886\n",
      "[148]\ttrain-logloss:0.22461\ttrain-amex:0.78925\teval-logloss:0.23101\teval-amex:0.77929\n",
      "[149]\ttrain-logloss:0.22441\ttrain-amex:0.78946\teval-logloss:0.23084\teval-amex:0.77966\n",
      "[150]\ttrain-logloss:0.22421\ttrain-amex:0.78965\teval-logloss:0.23069\teval-amex:0.78000\n",
      "[151]\ttrain-logloss:0.22400\ttrain-amex:0.78990\teval-logloss:0.23051\teval-amex:0.77948\n",
      "[152]\ttrain-logloss:0.22379\ttrain-amex:0.79009\teval-logloss:0.23033\teval-amex:0.77956\n",
      "[153]\ttrain-logloss:0.22361\ttrain-amex:0.79020\teval-logloss:0.23017\teval-amex:0.77944\n",
      "[154]\ttrain-logloss:0.22340\ttrain-amex:0.79040\teval-logloss:0.23002\teval-amex:0.77982\n",
      "[155]\ttrain-logloss:0.22320\ttrain-amex:0.79059\teval-logloss:0.22987\teval-amex:0.77987\n",
      "[156]\ttrain-logloss:0.22300\ttrain-amex:0.79070\teval-logloss:0.22971\teval-amex:0.77981\n",
      "[157]\ttrain-logloss:0.22282\ttrain-amex:0.79085\teval-logloss:0.22957\teval-amex:0.78005\n",
      "[158]\ttrain-logloss:0.22262\ttrain-amex:0.79110\teval-logloss:0.22942\teval-amex:0.78015\n",
      "[159]\ttrain-logloss:0.22242\ttrain-amex:0.79105\teval-logloss:0.22927\teval-amex:0.78036\n",
      "[160]\ttrain-logloss:0.22223\ttrain-amex:0.79142\teval-logloss:0.22912\teval-amex:0.78063\n",
      "[161]\ttrain-logloss:0.22204\ttrain-amex:0.79169\teval-logloss:0.22896\teval-amex:0.78088\n",
      "[162]\ttrain-logloss:0.22188\ttrain-amex:0.79188\teval-logloss:0.22882\teval-amex:0.78087\n",
      "[163]\ttrain-logloss:0.22171\ttrain-amex:0.79204\teval-logloss:0.22868\teval-amex:0.78100\n",
      "[164]\ttrain-logloss:0.22153\ttrain-amex:0.79226\teval-logloss:0.22855\teval-amex:0.78103\n",
      "[165]\ttrain-logloss:0.22136\ttrain-amex:0.79248\teval-logloss:0.22842\teval-amex:0.78110\n",
      "[166]\ttrain-logloss:0.22118\ttrain-amex:0.79268\teval-logloss:0.22829\teval-amex:0.78148\n",
      "[167]\ttrain-logloss:0.22104\ttrain-amex:0.79273\teval-logloss:0.22818\teval-amex:0.78138\n",
      "[168]\ttrain-logloss:0.22090\ttrain-amex:0.79286\teval-logloss:0.22807\teval-amex:0.78142\n",
      "[169]\ttrain-logloss:0.22074\ttrain-amex:0.79303\teval-logloss:0.22795\teval-amex:0.78151\n",
      "[170]\ttrain-logloss:0.22056\ttrain-amex:0.79319\teval-logloss:0.22783\teval-amex:0.78167\n",
      "[171]\ttrain-logloss:0.22039\ttrain-amex:0.79333\teval-logloss:0.22769\teval-amex:0.78227\n",
      "[172]\ttrain-logloss:0.22023\ttrain-amex:0.79352\teval-logloss:0.22757\teval-amex:0.78225\n",
      "[173]\ttrain-logloss:0.22006\ttrain-amex:0.79370\teval-logloss:0.22745\teval-amex:0.78230\n",
      "[174]\ttrain-logloss:0.21988\ttrain-amex:0.79388\teval-logloss:0.22733\teval-amex:0.78247\n",
      "[175]\ttrain-logloss:0.21972\ttrain-amex:0.79399\teval-logloss:0.22721\teval-amex:0.78259\n",
      "[176]\ttrain-logloss:0.21956\ttrain-amex:0.79413\teval-logloss:0.22710\teval-amex:0.78264\n",
      "[177]\ttrain-logloss:0.21940\ttrain-amex:0.79434\teval-logloss:0.22700\teval-amex:0.78296\n",
      "[178]\ttrain-logloss:0.21925\ttrain-amex:0.79456\teval-logloss:0.22689\teval-amex:0.78284\n",
      "[179]\ttrain-logloss:0.21909\ttrain-amex:0.79467\teval-logloss:0.22677\teval-amex:0.78318\n",
      "[180]\ttrain-logloss:0.21895\ttrain-amex:0.79482\teval-logloss:0.22668\teval-amex:0.78310\n",
      "[181]\ttrain-logloss:0.21880\ttrain-amex:0.79501\teval-logloss:0.22658\teval-amex:0.78360\n",
      "[182]\ttrain-logloss:0.21866\ttrain-amex:0.79505\teval-logloss:0.22648\teval-amex:0.78354\n",
      "[183]\ttrain-logloss:0.21850\ttrain-amex:0.79529\teval-logloss:0.22637\teval-amex:0.78363\n",
      "[184]\ttrain-logloss:0.21835\ttrain-amex:0.79553\teval-logloss:0.22626\teval-amex:0.78370\n",
      "[185]\ttrain-logloss:0.21819\ttrain-amex:0.79569\teval-logloss:0.22616\teval-amex:0.78383\n",
      "[186]\ttrain-logloss:0.21805\ttrain-amex:0.79577\teval-logloss:0.22607\teval-amex:0.78407\n",
      "[187]\ttrain-logloss:0.21790\ttrain-amex:0.79595\teval-logloss:0.22597\teval-amex:0.78439\n",
      "[188]\ttrain-logloss:0.21776\ttrain-amex:0.79616\teval-logloss:0.22588\teval-amex:0.78443\n",
      "[189]\ttrain-logloss:0.21761\ttrain-amex:0.79621\teval-logloss:0.22579\teval-amex:0.78422\n",
      "[190]\ttrain-logloss:0.21748\ttrain-amex:0.79636\teval-logloss:0.22570\teval-amex:0.78437\n",
      "[191]\ttrain-logloss:0.21735\ttrain-amex:0.79666\teval-logloss:0.22563\teval-amex:0.78447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192]\ttrain-logloss:0.21722\ttrain-amex:0.79691\teval-logloss:0.22555\teval-amex:0.78462\n",
      "[193]\ttrain-logloss:0.21709\ttrain-amex:0.79699\teval-logloss:0.22547\teval-amex:0.78449\n",
      "[194]\ttrain-logloss:0.21695\ttrain-amex:0.79722\teval-logloss:0.22540\teval-amex:0.78467\n",
      "[195]\ttrain-logloss:0.21683\ttrain-amex:0.79742\teval-logloss:0.22532\teval-amex:0.78492\n",
      "[196]\ttrain-logloss:0.21669\ttrain-amex:0.79751\teval-logloss:0.22523\teval-amex:0.78468\n",
      "[197]\ttrain-logloss:0.21658\ttrain-amex:0.79748\teval-logloss:0.22516\teval-amex:0.78495\n",
      "[198]\ttrain-logloss:0.21647\ttrain-amex:0.79764\teval-logloss:0.22509\teval-amex:0.78478\n",
      "[199]\ttrain-logloss:0.21635\ttrain-amex:0.79787\teval-logloss:0.22501\teval-amex:0.78486\n",
      "[200]\ttrain-logloss:0.21624\ttrain-amex:0.79817\teval-logloss:0.22494\teval-amex:0.78502\n",
      "[201]\ttrain-logloss:0.21612\ttrain-amex:0.79834\teval-logloss:0.22487\teval-amex:0.78527\n",
      "[202]\ttrain-logloss:0.21599\ttrain-amex:0.79851\teval-logloss:0.22478\teval-amex:0.78524\n",
      "[203]\ttrain-logloss:0.21586\ttrain-amex:0.79862\teval-logloss:0.22470\teval-amex:0.78548\n",
      "[204]\ttrain-logloss:0.21577\ttrain-amex:0.79870\teval-logloss:0.22464\teval-amex:0.78549\n",
      "[205]\ttrain-logloss:0.21564\ttrain-amex:0.79889\teval-logloss:0.22456\teval-amex:0.78572\n",
      "[206]\ttrain-logloss:0.21551\ttrain-amex:0.79909\teval-logloss:0.22447\teval-amex:0.78587\n",
      "[207]\ttrain-logloss:0.21542\ttrain-amex:0.79906\teval-logloss:0.22441\teval-amex:0.78556\n",
      "[208]\ttrain-logloss:0.21529\ttrain-amex:0.79913\teval-logloss:0.22433\teval-amex:0.78575\n",
      "[209]\ttrain-logloss:0.21516\ttrain-amex:0.79928\teval-logloss:0.22424\teval-amex:0.78571\n",
      "[210]\ttrain-logloss:0.21503\ttrain-amex:0.79962\teval-logloss:0.22416\teval-amex:0.78580\n",
      "[211]\ttrain-logloss:0.21492\ttrain-amex:0.79965\teval-logloss:0.22408\teval-amex:0.78599\n",
      "[212]\ttrain-logloss:0.21482\ttrain-amex:0.79966\teval-logloss:0.22403\teval-amex:0.78588\n",
      "[213]\ttrain-logloss:0.21473\ttrain-amex:0.79976\teval-logloss:0.22396\teval-amex:0.78612\n",
      "[214]\ttrain-logloss:0.21462\ttrain-amex:0.79983\teval-logloss:0.22388\teval-amex:0.78626\n",
      "[215]\ttrain-logloss:0.21451\ttrain-amex:0.80008\teval-logloss:0.22381\teval-amex:0.78602\n",
      "[216]\ttrain-logloss:0.21441\ttrain-amex:0.80020\teval-logloss:0.22375\teval-amex:0.78625\n",
      "[217]\ttrain-logloss:0.21431\ttrain-amex:0.80047\teval-logloss:0.22369\teval-amex:0.78640\n",
      "[218]\ttrain-logloss:0.21421\ttrain-amex:0.80059\teval-logloss:0.22363\teval-amex:0.78652\n",
      "[219]\ttrain-logloss:0.21409\ttrain-amex:0.80070\teval-logloss:0.22357\teval-amex:0.78643\n",
      "[220]\ttrain-logloss:0.21400\ttrain-amex:0.80077\teval-logloss:0.22352\teval-amex:0.78640\n",
      "[221]\ttrain-logloss:0.21390\ttrain-amex:0.80112\teval-logloss:0.22346\teval-amex:0.78652\n",
      "[222]\ttrain-logloss:0.21378\ttrain-amex:0.80134\teval-logloss:0.22339\teval-amex:0.78644\n",
      "[223]\ttrain-logloss:0.21367\ttrain-amex:0.80140\teval-logloss:0.22332\teval-amex:0.78646\n",
      "[224]\ttrain-logloss:0.21358\ttrain-amex:0.80149\teval-logloss:0.22326\teval-amex:0.78635\n",
      "[225]\ttrain-logloss:0.21346\ttrain-amex:0.80167\teval-logloss:0.22319\teval-amex:0.78656\n",
      "[226]\ttrain-logloss:0.21335\ttrain-amex:0.80191\teval-logloss:0.22313\teval-amex:0.78698\n",
      "[227]\ttrain-logloss:0.21326\ttrain-amex:0.80202\teval-logloss:0.22308\teval-amex:0.78700\n",
      "[228]\ttrain-logloss:0.21316\ttrain-amex:0.80215\teval-logloss:0.22302\teval-amex:0.78697\n",
      "[229]\ttrain-logloss:0.21309\ttrain-amex:0.80236\teval-logloss:0.22296\teval-amex:0.78707\n",
      "[230]\ttrain-logloss:0.21297\ttrain-amex:0.80257\teval-logloss:0.22290\teval-amex:0.78705\n",
      "[231]\ttrain-logloss:0.21288\ttrain-amex:0.80270\teval-logloss:0.22286\teval-amex:0.78715\n",
      "[232]\ttrain-logloss:0.21275\ttrain-amex:0.80289\teval-logloss:0.22279\teval-amex:0.78698\n",
      "[233]\ttrain-logloss:0.21263\ttrain-amex:0.80298\teval-logloss:0.22273\teval-amex:0.78706\n",
      "[234]\ttrain-logloss:0.21252\ttrain-amex:0.80314\teval-logloss:0.22266\teval-amex:0.78725\n",
      "[235]\ttrain-logloss:0.21244\ttrain-amex:0.80320\teval-logloss:0.22261\teval-amex:0.78733\n",
      "[236]\ttrain-logloss:0.21234\ttrain-amex:0.80329\teval-logloss:0.22256\teval-amex:0.78737\n",
      "[237]\ttrain-logloss:0.21224\ttrain-amex:0.80341\teval-logloss:0.22250\teval-amex:0.78760\n",
      "[238]\ttrain-logloss:0.21214\ttrain-amex:0.80360\teval-logloss:0.22245\teval-amex:0.78774\n",
      "[239]\ttrain-logloss:0.21205\ttrain-amex:0.80365\teval-logloss:0.22241\teval-amex:0.78781\n",
      "[240]\ttrain-logloss:0.21193\ttrain-amex:0.80375\teval-logloss:0.22236\teval-amex:0.78772\n",
      "[241]\ttrain-logloss:0.21184\ttrain-amex:0.80385\teval-logloss:0.22231\teval-amex:0.78776\n",
      "[242]\ttrain-logloss:0.21173\ttrain-amex:0.80408\teval-logloss:0.22225\teval-amex:0.78799\n",
      "[243]\ttrain-logloss:0.21163\ttrain-amex:0.80427\teval-logloss:0.22220\teval-amex:0.78773\n",
      "[244]\ttrain-logloss:0.21151\ttrain-amex:0.80445\teval-logloss:0.22214\teval-amex:0.78808\n",
      "[245]\ttrain-logloss:0.21143\ttrain-amex:0.80457\teval-logloss:0.22210\teval-amex:0.78814\n",
      "[246]\ttrain-logloss:0.21134\ttrain-amex:0.80470\teval-logloss:0.22205\teval-amex:0.78809\n",
      "[247]\ttrain-logloss:0.21124\ttrain-amex:0.80482\teval-logloss:0.22199\teval-amex:0.78813\n",
      "[248]\ttrain-logloss:0.21113\ttrain-amex:0.80496\teval-logloss:0.22195\teval-amex:0.78818\n",
      "[249]\ttrain-logloss:0.21105\ttrain-amex:0.80504\teval-logloss:0.22190\teval-amex:0.78826\n",
      "[250]\ttrain-logloss:0.21098\ttrain-amex:0.80501\teval-logloss:0.22185\teval-amex:0.78855\n",
      "[251]\ttrain-logloss:0.21088\ttrain-amex:0.80514\teval-logloss:0.22181\teval-amex:0.78825\n",
      "[252]\ttrain-logloss:0.21080\ttrain-amex:0.80523\teval-logloss:0.22176\teval-amex:0.78839\n",
      "[253]\ttrain-logloss:0.21071\ttrain-amex:0.80548\teval-logloss:0.22170\teval-amex:0.78850\n",
      "[254]\ttrain-logloss:0.21063\ttrain-amex:0.80564\teval-logloss:0.22165\teval-amex:0.78861\n",
      "[255]\ttrain-logloss:0.21052\ttrain-amex:0.80593\teval-logloss:0.22160\teval-amex:0.78880\n",
      "[256]\ttrain-logloss:0.21042\ttrain-amex:0.80609\teval-logloss:0.22155\teval-amex:0.78875\n",
      "[257]\ttrain-logloss:0.21031\ttrain-amex:0.80624\teval-logloss:0.22150\teval-amex:0.78850\n",
      "[258]\ttrain-logloss:0.21022\ttrain-amex:0.80650\teval-logloss:0.22145\teval-amex:0.78887\n",
      "[259]\ttrain-logloss:0.21012\ttrain-amex:0.80673\teval-logloss:0.22142\teval-amex:0.78890\n",
      "[260]\ttrain-logloss:0.21005\ttrain-amex:0.80674\teval-logloss:0.22137\teval-amex:0.78910\n",
      "[261]\ttrain-logloss:0.20997\ttrain-amex:0.80680\teval-logloss:0.22133\teval-amex:0.78899\n",
      "[262]\ttrain-logloss:0.20989\ttrain-amex:0.80700\teval-logloss:0.22129\teval-amex:0.78923\n",
      "[263]\ttrain-logloss:0.20983\ttrain-amex:0.80714\teval-logloss:0.22125\teval-amex:0.78937\n",
      "[264]\ttrain-logloss:0.20974\ttrain-amex:0.80723\teval-logloss:0.22121\teval-amex:0.78938\n",
      "[265]\ttrain-logloss:0.20965\ttrain-amex:0.80735\teval-logloss:0.22116\teval-amex:0.78921\n",
      "[266]\ttrain-logloss:0.20953\ttrain-amex:0.80755\teval-logloss:0.22111\teval-amex:0.78954\n",
      "[267]\ttrain-logloss:0.20946\ttrain-amex:0.80757\teval-logloss:0.22107\teval-amex:0.78943\n",
      "[268]\ttrain-logloss:0.20940\ttrain-amex:0.80768\teval-logloss:0.22103\teval-amex:0.78967\n",
      "[269]\ttrain-logloss:0.20931\ttrain-amex:0.80786\teval-logloss:0.22100\teval-amex:0.78951\n",
      "[270]\ttrain-logloss:0.20924\ttrain-amex:0.80795\teval-logloss:0.22096\teval-amex:0.78963\n",
      "[271]\ttrain-logloss:0.20917\ttrain-amex:0.80787\teval-logloss:0.22093\teval-amex:0.78973\n",
      "[272]\ttrain-logloss:0.20911\ttrain-amex:0.80792\teval-logloss:0.22089\teval-amex:0.78976\n",
      "[273]\ttrain-logloss:0.20903\ttrain-amex:0.80802\teval-logloss:0.22085\teval-amex:0.78977\n",
      "[274]\ttrain-logloss:0.20898\ttrain-amex:0.80815\teval-logloss:0.22082\teval-amex:0.78993\n",
      "[275]\ttrain-logloss:0.20891\ttrain-amex:0.80836\teval-logloss:0.22078\teval-amex:0.79005\n",
      "[276]\ttrain-logloss:0.20884\ttrain-amex:0.80840\teval-logloss:0.22076\teval-amex:0.79010\n",
      "[277]\ttrain-logloss:0.20875\ttrain-amex:0.80844\teval-logloss:0.22071\teval-amex:0.79026\n",
      "[278]\ttrain-logloss:0.20870\ttrain-amex:0.80862\teval-logloss:0.22068\teval-amex:0.79027\n",
      "[279]\ttrain-logloss:0.20863\ttrain-amex:0.80868\teval-logloss:0.22065\teval-amex:0.79053\n",
      "[280]\ttrain-logloss:0.20855\ttrain-amex:0.80888\teval-logloss:0.22061\teval-amex:0.79053\n",
      "[281]\ttrain-logloss:0.20847\ttrain-amex:0.80897\teval-logloss:0.22057\teval-amex:0.79050\n",
      "[282]\ttrain-logloss:0.20842\ttrain-amex:0.80906\teval-logloss:0.22053\teval-amex:0.79043\n",
      "[283]\ttrain-logloss:0.20832\ttrain-amex:0.80915\teval-logloss:0.22049\teval-amex:0.79042\n",
      "[284]\ttrain-logloss:0.20825\ttrain-amex:0.80932\teval-logloss:0.22044\teval-amex:0.79050\n",
      "[285]\ttrain-logloss:0.20819\ttrain-amex:0.80940\teval-logloss:0.22042\teval-amex:0.79036\n",
      "[286]\ttrain-logloss:0.20811\ttrain-amex:0.80962\teval-logloss:0.22039\teval-amex:0.79047\n",
      "[287]\ttrain-logloss:0.20802\ttrain-amex:0.80982\teval-logloss:0.22035\teval-amex:0.79051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[288]\ttrain-logloss:0.20794\ttrain-amex:0.80990\teval-logloss:0.22031\teval-amex:0.79029\n",
      "[289]\ttrain-logloss:0.20784\ttrain-amex:0.81007\teval-logloss:0.22027\teval-amex:0.79055\n",
      "[290]\ttrain-logloss:0.20775\ttrain-amex:0.81012\teval-logloss:0.22023\teval-amex:0.79071\n",
      "[291]\ttrain-logloss:0.20768\ttrain-amex:0.81023\teval-logloss:0.22020\teval-amex:0.79091\n",
      "[292]\ttrain-logloss:0.20761\ttrain-amex:0.81037\teval-logloss:0.22018\teval-amex:0.79106\n",
      "[293]\ttrain-logloss:0.20753\ttrain-amex:0.81048\teval-logloss:0.22016\teval-amex:0.79086\n",
      "[294]\ttrain-logloss:0.20748\ttrain-amex:0.81052\teval-logloss:0.22013\teval-amex:0.79099\n",
      "[295]\ttrain-logloss:0.20742\ttrain-amex:0.81055\teval-logloss:0.22010\teval-amex:0.79088\n",
      "[296]\ttrain-logloss:0.20733\ttrain-amex:0.81088\teval-logloss:0.22007\teval-amex:0.79114\n",
      "[297]\ttrain-logloss:0.20726\ttrain-amex:0.81094\teval-logloss:0.22004\teval-amex:0.79132\n",
      "[298]\ttrain-logloss:0.20718\ttrain-amex:0.81115\teval-logloss:0.22001\teval-amex:0.79131\n",
      "[299]\ttrain-logloss:0.20711\ttrain-amex:0.81131\teval-logloss:0.21997\teval-amex:0.79132\n",
      "[300]\ttrain-logloss:0.20704\ttrain-amex:0.81138\teval-logloss:0.21995\teval-amex:0.79156\n",
      "[301]\ttrain-logloss:0.20698\ttrain-amex:0.81142\teval-logloss:0.21993\teval-amex:0.79131\n",
      "[302]\ttrain-logloss:0.20691\ttrain-amex:0.81175\teval-logloss:0.21990\teval-amex:0.79126\n",
      "[303]\ttrain-logloss:0.20683\ttrain-amex:0.81187\teval-logloss:0.21986\teval-amex:0.79131\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary:logistic\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_metric\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbooster\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdart\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     28\u001b[0m           }\n\u001b[1;32m     29\u001b[0m watchlist \u001b[38;5;241m=\u001b[39m [(dtrain, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m), (dvalid, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m---> 30\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwatchlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mxgb_amex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest ntree_limit:\u001b[39m\u001b[38;5;124m'\u001b[39m, model\u001b[38;5;241m.\u001b[39mbest_ntree_limit)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest score:\u001b[39m\u001b[38;5;124m'\u001b[39m, model\u001b[38;5;241m.\u001b[39mbest_score)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py:188\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(params, dtrain, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, evals\u001b[38;5;241m=\u001b[39m(), obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, feval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    116\u001b[0m           maximize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, evals_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    117\u001b[0m           verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xgb_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;124;03m\"\"\"Train a booster with given parameters.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    Booster : a trained booster model\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     bst \u001b[38;5;241m=\u001b[39m \u001b[43m_train_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bst\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py:82\u001b[0m, in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     85\u001b[0m bst \u001b[38;5;241m=\u001b[39m callbacks\u001b[38;5;241m.\u001b[39mafter_training(bst)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/callback.py:434\u001b[0m, in \u001b[0;36mCallbackContainer.after_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name \u001b[38;5;129;01min\u001b[39;00m evals:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m name\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset name should not contain `-`\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 434\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m score \u001b[38;5;241m=\u001b[39m score\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# into datasets\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# split up `test-error:0.1234`\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:1744\u001b[0m, in \u001b[0;36mBooster.eval_set\u001b[0;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[1;32m   1742\u001b[0m evnames \u001b[38;5;241m=\u001b[39m c_array(ctypes\u001b[38;5;241m.\u001b[39mc_char_p, [c_str(d[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m evals])\n\u001b[1;32m   1743\u001b[0m msg \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p()\n\u001b[0;32m-> 1744\u001b[0m _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterEvalOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mdmats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mc_bst_ulong\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1749\u001b[0m res \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdecode()  \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a numpy array to store test predictions\n",
    "test_predictions = np.zeros(len(test))\n",
    "# Create a numpy array to store out of folds predictions\n",
    "oof_predictions = np.zeros(len(train))\n",
    "kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train['target'])):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {len(features)} features...')\n",
    "    x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "    y_train, y_val = train['target'].iloc[trn_ind], train['target'].iloc[val_ind]\n",
    "\n",
    "    dtrain = xgb.DMatrix(data = x_train, label = y_train)\n",
    "    dvalid = xgb.DMatrix(data = x_val, label = y_val)\n",
    "    params = {'objective': 'binary:logistic',\n",
    "            \"eval_metric\": \"logloss\",\n",
    "            'booster': 'dart',\n",
    "            'seed': 42,\n",
    "            'min_child_weight':3.529045008103897,\n",
    "            'eta': 0.03,\n",
    "            'subsample': 0.8639467537456698,\n",
    "            'colsample_bytree':0.6059132895850072,\n",
    "            'lambda': 70,\n",
    "            'max_depth': 7,\n",
    "            'gamma':2.5764715666738445,\n",
    "            'tree_method': 'hist',\n",
    "            'n_jobs':-1\n",
    "              }\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    model = xgb.train(params, dtrain = dtrain, num_boost_round = 5000, evals = watchlist, \\\n",
    "                      early_stopping_rounds = 150, feval = xgb_amex, maximize = True, verbose_eval = 1)\n",
    "    print('best ntree_limit:', model.best_ntree_limit)\n",
    "    print('best score:', model.best_score)\n",
    "    \n",
    "    plt.figure(figsize=(20,15))\n",
    "    xgb.plot_importance(model, max_num_features=20)\n",
    "    print(plt.show())\n",
    "    \n",
    "\n",
    "    # Save best model\n",
    "    model.save_model(f'xgboost_fold{fold}_addlag_tune.json')\n",
    "    # Predict validation\n",
    "    val_pred = model.predict(xgb.DMatrix(x_val), iteration_range=(0, model.best_ntree_limit))\n",
    "    \n",
    "    \n",
    "    # Add to out of folds array\n",
    "    oof_predictions[val_ind] = val_pred\n",
    "    # Predict the test set\n",
    "    test_pred = model.predict(xgb.DMatrix(test[features]), iteration_range = (0, model.best_ntree_limit))\n",
    "\n",
    "    test_predictions += test_pred / 5\n",
    "    # Compute fold metric\n",
    "    score = amex_metric(y_val, val_pred)\n",
    "    print(f'Our fold {fold} CV score is {score}')\n",
    "    del x_train, x_val, y_train, y_val\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0798fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute out of folds metric\n",
    "score = amex_metric(train['target'], oof_predictions)\n",
    "print(f'Our out of folds CV score is {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4ff5198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to store out of folds predictions\n",
    "oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train['target'], 'prediction': oof_predictions})\n",
    "oof_df.to_csv('oof_xgboost_addlag_tune.csv', index = False)\n",
    "# Create a dataframe to store test prediction\n",
    "test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "test_df.to_csv('sub_xgboost_addlag_tune.csv', index = False) #0.796"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63f91f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
